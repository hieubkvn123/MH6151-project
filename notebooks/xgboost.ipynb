{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c0d322b",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcceecdc",
   "metadata": {},
   "source": [
    "# Data preprocessing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67dc6123",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "job_labelenc = LabelEncoder()\n",
    "marital_labelenc = LabelEncoder()\n",
    "contact_labelenc = LabelEncoder()\n",
    "poutcome_labelenc = LabelEncoder()\n",
    "\n",
    "def preproc_education(x):\n",
    "    if(x == 'unknown') : return 0\n",
    "    elif(x == 'primary') : return 1\n",
    "    elif(x == 'secondary') : return 2\n",
    "    elif(x == 'tertiary') : return 3\n",
    "    \n",
    "def preproc_month(x):\n",
    "    if(x == 'jan') : return 1\n",
    "    elif(x == 'feb') : return 2\n",
    "    elif(x == 'mar') : return 3\n",
    "    elif(x == 'apr') : return 4\n",
    "    elif(x == 'may') : return 5\n",
    "    elif(x == 'jun') : return 6\n",
    "    elif(x == 'jul') : return 7\n",
    "    elif(x == 'aug') : return 8\n",
    "    elif(x == 'sep') : return 9\n",
    "    elif(x == 'oct') : return 10\n",
    "    elif(x == 'nov') : return 11\n",
    "    elif(x == 'dec') : return 12\n",
    "    \n",
    "def preproc_binary(x):\n",
    "    if(x == 'no') : return 0\n",
    "    elif(x == 'yes') : return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd9ac9",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a51fa6",
   "metadata": {},
   "source": [
    "### Search for the best parameters using GridSearchCV\n",
    "\n",
    "Default validation for GridSearchCV is 5-fold cross validation, hence we will keep it at default state\n",
    "\n",
    "#### Best parameters are scored based on accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88bddc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, train_test_split\n",
    "\n",
    "# list down the parameters to search\n",
    "max_depth = [2,3,4,5]\n",
    "min_child_weight = [1,2,3]\n",
    "learning_rate = [0.1,0.15,0.2]\n",
    "eta = [0.2,0.3]\n",
    "\n",
    "\n",
    "param_grid = dict(\n",
    "    learning_rate=learning_rate,\n",
    "    min_child_weight=min_child_weight,\n",
    "    max_depth=max_depth,\n",
    "    eta = eta\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc963ad1",
   "metadata": {},
   "source": [
    "# Oversampled data should go in the below cell -> df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af42d326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the train data for modelling\n",
    "\n",
    "# Re-read\n",
    "df = pd.read_csv(data_file)\n",
    "\n",
    "# Rename last column|\n",
    "df = df.rename(columns={'y' : 'subscription'})\n",
    "\n",
    "# ALl preprocessing steps\n",
    "df['job'] = job_labelenc.fit_transform(df['job'])\n",
    "df['marital'] = marital_labelenc.fit_transform(df['marital'])\n",
    "df['contact'] = contact_labelenc.fit_transform(df['contact'])\n",
    "df['poutcome'] = poutcome_labelenc.fit_transform(df['poutcome'])\n",
    "df['education'] = df['education'].apply(preproc_education)\n",
    "df['month'] = df['month'].apply(preproc_month)\n",
    "df['default'] = df['default'].apply(preproc_binary)\n",
    "df['housing'] = df['housing'].apply(preproc_binary)\n",
    "df['loan'] = df['loan'].apply(preproc_binary)\n",
    "\n",
    "\n",
    "target_col = 'subscription'\n",
    "feat_cols = [col for col in df.columns if col != 'subscription']\n",
    "\n",
    "df['subscription'] = df['subscription'].replace({'yes': 1, 'no': 0})\n",
    "\n",
    "y = df[target_col]\n",
    "X = df.drop(columns = [target_col, \"Unnamed: 0\",'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dafee384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum parameters:  {'eta': 0.2, 'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 2}\n",
      "Accuracy:  0.9032570227825703\n"
     ]
    }
   ],
   "source": [
    "#train the data\n",
    "#scoring base on accuracy\n",
    "xgb_model = XGBClassifier(random_state=1, verbosity=1, objective =\"binary:logistic\",\n",
    "                         tree_method = \"gpu_hist\", device =\"cuda\")\n",
    "\n",
    "# Start validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy'\n",
    "                           )\n",
    "\n",
    "best_model = grid_search.fit(X, y)\n",
    "\n",
    "#print the best parameters\n",
    "print('Optimum parameters: ', best_model.best_params_)\n",
    "print('Accuracy: ', best_model.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af6cac60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.2, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.2, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.2, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalise our model using the best parameters found\n",
    "xgb_model = XGBClassifier(random_state=1, verbosity=1, objective=\"binary:logistic\", \n",
    "                                   learning_rate=0.1,max_depth=5,min_child_weight=2,\n",
    "                                   eta=0.2,tree_method = \"gpu_hist\", device =\"cuda\")\n",
    "xgb_model.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36617e47",
   "metadata": {},
   "source": [
    "### Test our prediction against the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69790f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare test data \n",
    "test_file = '../data/bank-test.csv'\n",
    "\n",
    "# Re-read\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "# Rename last column|\n",
    "df_test = df_test.rename(columns={'y' : 'subscription'})\n",
    "\n",
    "# ALl preprocessing steps\n",
    "df_test['job'] = job_labelenc.fit_transform(df_test['job'])\n",
    "df_test['marital'] = marital_labelenc.fit_transform(df_test['marital'])\n",
    "df_test['contact'] = contact_labelenc.fit_transform(df_test['contact'])\n",
    "df_test['poutcome'] = poutcome_labelenc.fit_transform(df_test['poutcome'])\n",
    "df_test['education'] = df_test['education'].apply(preproc_education)\n",
    "df_test['month'] = df_test['month'].apply(preproc_month)\n",
    "df_test['default'] = df_test['default'].apply(preproc_binary)\n",
    "df_test['housing'] = df_test['housing'].apply(preproc_binary)\n",
    "df_test['loan'] = df_test['loan'].apply(preproc_binary)\n",
    "\n",
    "X_test = df_test.drop(columns = [target_col, \"Unnamed: 0\",'duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91b4de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our model to predict\n",
    "pred = xgb_model.predict(X_test)\n",
    "pred_dt = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83feae95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Score: 0.3582787556836247\n"
     ]
    }
   ],
   "source": [
    "# Convert ground truth values from \"no\" and \"yes\" to 0 and 1 (same format as our prediction)\n",
    "ground_truth = df_test['subscription']\n",
    "ground_truth_binary = [0 if val == \"no\" else 1 for val in ground_truth]\n",
    "\n",
    "# Compute MCC\n",
    "mcc_score = matthews_corrcoef(ground_truth_binary, pred_dt)\n",
    "print(\"MCC Score:\", mcc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d052ae",
   "metadata": {},
   "source": [
    "### Improving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "850ea604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-initialise the train data\n",
    "df_train = df\n",
    "\n",
    "y = df_train[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab9850a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The importance of feature age is 3.83 %.\n",
      "The importance of feature job is 1.23 %.\n",
      "The importance of feature marital is 2.15 %.\n",
      "The importance of feature education is 2.06 %.\n",
      "The importance of feature default is 1.02 %.\n",
      "The importance of feature balance is 1.91 %.\n",
      "The importance of feature housing is 13.9 %.\n",
      "The importance of feature loan is 6.8 %.\n",
      "The importance of feature contact is 20.95 %.\n",
      "The importance of feature day is 3.07 %.\n",
      "The importance of feature month is 5.55 %.\n",
      "The importance of feature campaign is 2.79 %.\n",
      "The importance of feature pdays is 6.05 %.\n",
      "The importance of feature previous is 2.12 %.\n",
      "The importance of feature poutcome is 26.58 %.\n"
     ]
    }
   ],
   "source": [
    "#check for the feature's importance\n",
    "# we can drop those irrelevant ones and engineer more relevant ones\n",
    "importances = xgb_model.feature_importances_\n",
    "columns = X.columns\n",
    "i = 0\n",
    "\n",
    "while i < len(columns):\n",
    "    print(f\"The importance of feature {columns[i]} is {round(importances[i]*100, 2)} %.\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bb49199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineer\n",
    "#total number of days in the year, instead of day and month\n",
    "\n",
    "df_train['total days'] = df_train['month']*30 + df_train['day']\n",
    "\n",
    "# lets drop the ones with lower importance\n",
    "X_new = df_train.drop(columns = [target_col, \"job\",\"Unnamed: 0\",'month','day','duration'])\n",
    "\n",
    "# we note that there might be outliers\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Scale the specific column to reduce impact of outliers\n",
    "\n",
    "X_new['balance'] = scaler.fit_transform(X_new['balance'].values.reshape(-1, 1))\n",
    "X_new['age'] = scaler.fit_transform(X_new['age'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2ce656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list down the parameters to search\n",
    "max_depth = [4,6,7]\n",
    "min_child_weight = [2,3,4]\n",
    "learning_rate = [0.06,0.08,0.1]\n",
    "eta = [0.03,0.05,0.08]\n",
    "\n",
    "\n",
    "param_grid = dict(\n",
    "    learning_rate=learning_rate,\n",
    "    min_child_weight=min_child_weight,\n",
    "    max_depth=max_depth,\n",
    "    eta = eta\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1c0f33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum parameters:  {'eta': 0.03, 'learning_rate': 0.06, 'max_depth': 6, 'min_child_weight': 2}\n",
      "Accuracy:  0.9042800265428003\n"
     ]
    }
   ],
   "source": [
    "#retrain the data\n",
    "#scoring base on accuracy\n",
    "xgb_model = XGBClassifier(random_state=1, verbosity=1, objective =\"binary:logistic\",\n",
    "                         tree_method = \"gpu_hist\", device =\"cuda\")\n",
    "\n",
    "# Start validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy'\n",
    "                           )\n",
    "\n",
    "best_model = grid_search.fit(X_new, y)\n",
    "\n",
    "#print the best parameters\n",
    "print('Optimum parameters: ', best_model.best_params_)\n",
    "print('Accuracy: ', best_model.score(X_new, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc76b528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.03, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.06, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.03, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.06, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device='cuda', early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.03, eval_metric=None,\n",
       "              feature_types=None, gamma=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.06, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "              n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalise our model using the *new* best parameters found\n",
    "new_xgb_model = XGBClassifier(random_state=1, verbosity=1, objective=\"binary:logistic\", \n",
    "                                   learning_rate=0.06,max_depth=6,min_child_weight=2,\n",
    "                                   eta=0.03,tree_method = \"gpu_hist\", device =\"cuda\")\n",
    "new_xgb_model.fit(X_new,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fed48e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare test data again\n",
    "test_file = '../data/bank-test.csv'\n",
    "\n",
    "# Re-read\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "# Rename last column|\n",
    "df_test = df_test.rename(columns={'y' : 'subscription'})\n",
    "\n",
    "# ALl preprocessing steps\n",
    "df_test['job'] = job_labelenc.fit_transform(df_test['job'])\n",
    "df_test['marital'] = marital_labelenc.fit_transform(df_test['marital'])\n",
    "df_test['contact'] = contact_labelenc.fit_transform(df_test['contact'])\n",
    "df_test['poutcome'] = poutcome_labelenc.fit_transform(df_test['poutcome'])\n",
    "df_test['education'] = df_test['education'].apply(preproc_education)\n",
    "df_test['month'] = df_test['month'].apply(preproc_month)\n",
    "df_test['default'] = df_test['default'].apply(preproc_binary)\n",
    "df_test['housing'] = df_test['housing'].apply(preproc_binary)\n",
    "df_test['loan'] = df_test['loan'].apply(preproc_binary)\n",
    "\n",
    "#feature engineer\n",
    "df_test['total days'] = df_test['month']*30 + df_test['day']\n",
    "\n",
    "X_test = df_test.drop(columns = [target_col, \"Unnamed: 0\",\"job\",'month','day','duration'])\n",
    "\n",
    "# we did scaling in this new training, so test must follow\n",
    "X_test['balance'] = scaler.fit_transform(X_test['balance'].values.reshape(-1, 1))\n",
    "X_test['age'] = scaler.fit_transform(X_test['age'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f8f420a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our model to predict\n",
    "pred_new = new_xgb_model.predict(X_test)\n",
    "pred_dt = pd.DataFrame(pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0b4217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Score: 0.34314749939868844\n"
     ]
    }
   ],
   "source": [
    "# Convert ground truth values from \"no\" and \"yes\" to 0 and 1 (same format as our prediction)\n",
    "ground_truth = df_test['subscription']\n",
    "ground_truth_binary = [0 if val == \"no\" else 1 for val in ground_truth]\n",
    "\n",
    "# Compute MCC\n",
    "mcc_score = matthews_corrcoef(ground_truth_binary, pred_dt)\n",
    "print(\"MCC Score:\", mcc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2114ebb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
